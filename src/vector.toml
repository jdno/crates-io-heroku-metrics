# The API is needed for the load balancer health checks. Access to the proper
# API is prevented by nginx.
[api]
enabled = true
address = "0.0.0.0:8000"

# Collect internal Vector metrics, useful for debugging Vector issues in prod.
[sources.self]
type = "internal_metrics"

# Receive log messages from Heroku applications, using Heroku's Logplex system.
[sources.heroku]
type = "heroku_logs"
address = "0.0.0.0:8001"
encoding = "text"
query_parameters = ["app_name"]

# Publish all the collected metrics as a Prometheus exporter.
[sinks.prometheus]
type = "prometheus_exporter"
inputs = ["self", "heroku-postgres", "heroku-router-errors", "ingested-metrics"]
address = "0.0.0.0:8002"
# Long flush period needed due to Heroku Postgres's log frequency:
flush_period_secs = 600

###############################
#   Heroku Postgres metrics   #
###############################

# Heroku Postgres only outputs its metrics as a single log line roughly every 4
# to 5 minutes. The transform uses a custom Lua script to extract the metrics
# from the log line and emit separate Vector metrics for each extracted metric.
#
# A filter is used before the Lua script to quickly discard extra log lines.

[transforms.heroku-postgres-filter]
type = "filter"
inputs = ["heroku"]
condition = 'starts_with(.message, "source=HEROKU_POSTGRES") ?? false'

[transforms.heroku-postgres]
type = "lua"
version = "2"
inputs = ["heroku-postgres-filter"]
hooks.process = '''
function (event, emit)
    addon = string.match(event.log.message, "addon=([%w-]+)")

    for key, value in event.log.message:gmatch("sample#([%w-]+)=([^ ]+)") do
        multiply = 1

        -- Some samples are suffixed with "bytes", strip that
        value = value:gsub("bytes$", "")

        -- Some samples are suffixed with "kB", strip that and multiply by 1024
        without_kb = value:gsub("kB$", "")
        if without_kb ~= value then
            value = without_kb
            multiply = multiply * 1024
        end

        emit({
            ["metric"] = {
                ["gauge"] = {
                    ["value"] = tonumber(value) * multiply,
                },
                ["kind"] = "absolute",
                ["name"] = key:gsub("-", "_"),
                ["namespace"] = "heroku_postgres",
                ["tags"] = {
                    ["addon"] = addon,
                },
            }
        })
    end
end
'''

########################
#   Ingested metrics   #
########################

# Since it's not possible to point Prometheus to the individual Heroku dynos we
# changed the crates.io application to periodically print its metrics in the
# logs, relying on Vector to catch and expose them.
#
# The metrics line is prefixed with "crates-io-heroku-metrics:ingest" and
# contains the base64-encoded json-encoded metrics, formatted according to
# Vector's data model. After decoding the metrics from the log line the Lua
# transform enriches each metric with the app and process name, and emits each
# metric as an individual event.

[transforms.ingested-metrics-filter]
type = "filter"
inputs = ["heroku"]
condition = 'starts_with(.message, "crates-io-heroku-metrics:ingest ") ?? false'

[transforms.ingested-metrics-decode]
type = "remap"
inputs = ["ingested-metrics-filter"]
source = '.decoded = parse_json!(decode_base64!(replace!(.message, "crates-io-heroku-metrics:ingest ", "")))'

[transforms.ingested-metrics]
type = "lua"
version = "2"
inputs = ["ingested-metrics-decode"]
hooks.process = '''
function (event, emit)
    for _, metric in ipairs(event.log.decoded) do
        metric.metric.tags.app = event.log.app_name
        metric.metric.tags.process = event.log.proc_id
        emit(metric)
    end
end
'''

##############################
#   Heroku Router metrics    #
##############################

# The Heroku load balancer ("Router") does not emit metrics, but instead logs a
# line for every request or error, and it's our job to conver them to metrics.
#
# The `heroku-router-filter` -> `heroku-router-parse` transforms take care of
# decoding Heroku Router log messages, and then we use separate transforms for
# each metric we want to extract out of the logs.

[transforms.heroku-router-filter]
type = "filter"
inputs = ["heroku"]
condition = '.proc_id == "router"'

[transforms.heroku-router-parse]
type = "remap"
inputs = ["heroku-router-filter"]
# Merge into the log message data (".") the parsed key-value message.
source = '. |= parse_key_value!(.message)'

# Log lines with at=error represent one of the Heroku error codes, listed here:
#
#    https://devcenter.heroku.com/articles/error-codes
#
# We want to alert when they happen, so we generate metrics counting how many
# times they happen.

[transforms.heroku-router-errors-filter]
type = "filter"
inputs = ["heroku-router-parse"]
condition = '.at == "error"'

[transforms.heroku-router-errors]
type = "log_to_metric"
inputs = ["heroku-router-errors-filter"]
[[transforms.heroku-router-errors.metrics]]
type = "counter"
name = "errors"
field = "code" # Not sure why this is needed...
namespace = "heroku_router"
tags.code = "{{code}}"
tags.app = "{{app_name}}"
tags.dyno = "{{dyno}}"
