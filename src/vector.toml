# The API is needed for the load balancer health checks. Access to the proper
# API is prevented by nginx.
[api]
enabled = true
address = "0.0.0.0:8000"

# Collect internal Vector metrics, useful for debugging Vector issues in prod.
[sources.self]
type = "internal_metrics"

# Receive log messages from Heroku applications, using Heroku's Logplex system.
[sources.heroku]
type = "heroku_logs"
address = "0.0.0.0:8001"
encoding = "text"
query_parameters = ["app_name"]

# Publish all the collected metrics as a Prometheus exporter.
[sinks.prometheus]
type = "prometheus_exporter"
inputs = ["self", "heroku-postgres", "heroku-router-errors", "ingested-metrics"]
address = "0.0.0.0:8002"
# Long flush period needed due to Heroku Postgres's log frequency:
flush_period_secs = 600

###############################
#   Heroku Postgres metrics   #
###############################

# Heroku Postgres only outputs its metrics as a single log line roughly every 4
# to 5 minutes. The transform uses a custom Lua script to extract the metrics
# from the log line and emit separate Vector metrics for each extracted metric.
#
# A filter is used before the Lua script to quickly discard extra log lines.

[transforms.heroku-postgres-filter]
type = "filter"
inputs = ["heroku"]
condition = 'starts_with(.message, "source=HEROKU_POSTGRES") ?? false'

[transforms.heroku-postgres]
type = "lua"
version = "2"
inputs = ["heroku-postgres-filter"]
hooks.process = '''
function (event, emit)
    addon = string.match(event.log.message, "addon=([%w-]+)")

    for key, value in event.log.message:gmatch("sample#([%w-]+)=([^ ]+)") do
        multiply = 1

        -- Some samples are suffixed with "bytes", strip that
        value = value:gsub("bytes$", "")

        -- Some samples are suffixed with "kB", strip that and multiply by 1024
        without_kb = value:gsub("kB$", "")
        if without_kb ~= value then
            value = without_kb
            multiply = multiply * 1024
        end

        emit({
            ["metric"] = {
                ["gauge"] = {
                    ["value"] = tonumber(value) * multiply,
                },
                ["kind"] = "absolute",
                ["name"] = key:gsub("-", "_"),
                ["namespace"] = "heroku_postgres",
                ["tags"] = {
                    ["addon"] = addon,
                },
            }
        })
    end
end
'''

########################
#   Ingested metrics   #
########################

# Since it's not possible to point Prometheus to the individual Heroku dynos we
# changed the crates.io application to periodically print its metrics in the
# logs, relying on Vector to catch and expose them.
#
# The metrics line is prefixed with "crates-io-heroku-metrics:ingest" and
# contains the base64-encoded json-encoded metrics, formatted according to
# Vector's data model. After decoding the metrics from the log line the Lua
# transform enriches each metric with the app and process name, and emits each
# metric as an individual event.

[transforms.ingested-metrics-filter]
type = "filter"
inputs = ["heroku"]
condition = 'starts_with(.message, "crates-io-heroku-metrics:ingest ") ?? false'

[transforms.ingested-metrics-decode]
type = "remap"
inputs = ["ingested-metrics-filter"]
source = '.decoded = parse_json!(decode_base64!(replace!(.message, "crates-io-heroku-metrics:ingest ", "")))'

[transforms.ingested-metrics]
type = "lua"
version = "2"
inputs = ["ingested-metrics-decode"]
hooks.process = '''
function (event, emit)
    for _, metric in ipairs(event.log.decoded) do
        metric.metric.tags.app = event.log.app_name
        metric.metric.tags.process = event.log.proc_id
        emit(metric)
    end
end
'''

##############################
#   Heroku Router metrics    #
##############################

# The Heroku load balancer ("Router") does not emit metrics, but instead logs a
# line for every request or error, and it's our job to conver them to metrics.
#
# The `heroku-router-filter` -> `heroku-router-parse` transforms take care of
# decoding Heroku Router log messages, and then we use separate transforms for
# each metric we want to extract out of the logs.

[transforms.heroku-router-filter]
type = "filter"
inputs = ["heroku"]
condition = '.proc_id == "router"'

[transforms.heroku-router-parse]
type = "remap"
inputs = ["heroku-router-filter"]
# Merge into the log message data (".") the parsed key-value message.
source = '. |= parse_key_value!(.message)'

# We want to monitor the errors reported by the Heroku Router, and the next few
# transforms take care of that. The list of monitored error codes is defined in
# the transform, while the list of all error codes is available at:
#
#    https://devcenter.heroku.com/articles/error-codes
#
# Note that the implementation here is fairly weird due to a quirk in
# vector.dev. Heroku Router errors happen very rarely, but we still want to
# have those metrics to be present with a value of 0, so that we can alert
# based on them.
#
# Unfortunately vector.dev garbage collects metrics that have not been updated
# in a while, and since Heroku Router errors are rare that would happen all the
# time. To work around that, we emit a metric for each error code we care about
# for EVERY request, even successful ones, and we increment the metric by 0 or
# 1 depending on what the actual error code was.

[transforms.heroku-router-errors-map]
type = "remap"
inputs = ["heroku-router-parse"]
source = '''
recorded = [
    "H10", # App crashed
    "H11", # Backlog too deep
    "H12", # Request timeout
    "H13", # Connection closed without response
    "H14", # No web dynos running
    "H15", # Idle connection
    "H18", # Server request interrutped
    "H19", # Backend connection timeout
    "H20", # App boot timeout
    "H21", # Backend connection refused
    "H22", # Connection limiit reached
]

result = []
for_each(recorded) -> |_index, current_code| {
    increment_by = 0
    if .at != "info" && .code == current_code {
        increment_by = 1
    }
    result = push(result, {
        "code": current_code,
        "app": .app_name,
        "process": .dyno,
        "increment_by": increment_by,
    })
}

. = result
'''

[transforms.heroku-router-errors]
type = "log_to_metric"
inputs = ["heroku-router-errors-map"]
[[transforms.heroku-router-errors.metrics]]
type = "counter"
name = "errors"
namespace = "heroku_router"
tags.code = "{{code}}"
tags.app = "{{app}}"
tags.process = "{{process}}"
# Set the value of the metric to the "increment by" field.
field = "increment_by"
increment_by_value = true
